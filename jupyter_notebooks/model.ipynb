{"nbformat":4,"nbformat_minor":0,"metadata":{"orig_nbformat":2,"kernelspec":{"name":"python3","display_name":"Python 3","language":"python"},"colab":{"name":"model.ipynb","provenance":[],"collapsed_sections":[]},"language_info":{"name":"python","version":"3.9.2"},"accelerator":"GPU"},"cells":[{"cell_type":"markdown","metadata":{"id":"3bJ6ZZzry8Er"},"source":["# Song Lyric Generation Using Pure Next-word Prediction\n","\n","We define a simple RNN architecture, called `TokenRNN`, to perform pure next-word prediction for religious song lyric generation.\n","\n","This architecture was adapted from the PyTorch tutorial [NLP From Scratch: Translation with a Sequence to Sequence Network and Attention](https://pytorch.org/tutorials/intermediate/seq2seq_translation_tutorial.html)."]},{"cell_type":"code","metadata":{"id":"bQRi6xm5y8Es"},"source":["import os\n","import sys\n","import pickle\n","import torch\n","import torch.nn\n","import torch.optim\n","import torch.utils.data"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"butZqcQOzOHF","executionInfo":{"status":"ok","timestamp":1619640690525,"user_tz":240,"elapsed":811,"user":{"displayName":"Alexander DeRieux","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GjXMvSXQtaWB75iKecg6p0SbX3z5jmeUWh8Esnzkg=s64","userId":"11983099067437663618"}},"outputId":"b16a8722-f10d-498f-c551-dd556b04f91e"},"source":["\"\"\"Google Drive\"\"\"\n","from google.colab import drive\n","drive.mount('/content/gdrive/')\n","root_path = '/content/gdrive/My Drive/Virginia Tech/graduate/courses/2021_spring/ece_5424/assignments/project_ece_5424/'\n","# root_path = '/content/gdrive/My Drive/project_ece_5424/'\n","dataset_path = './dataset'\n","store_file = os.path.join(root_path,dataset_path,'lyrics.pickle')"],"execution_count":null,"outputs":[{"output_type":"stream","text":["Drive already mounted at /content/gdrive/; to attempt to forcibly remount, call drive.mount(\"/content/gdrive/\", force_remount=True).\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/","height":37},"id":"kTBOCijsy8Es","executionInfo":{"status":"ok","timestamp":1619640690525,"user_tz":240,"elapsed":786,"user":{"displayName":"Alexander DeRieux","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GjXMvSXQtaWB75iKecg6p0SbX3z5jmeUWh8Esnzkg=s64","userId":"11983099067437663618"}},"outputId":"9fc4c166-c61b-43a3-a3a7-1d4ced9be346"},"source":["\"\"\"Offline Usage\"\"\"\n","# dataset_path = '../../dataset'\n","# store_file = os.path.join(dataset_path,'lyrics.pickle')"],"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"application/vnd.google.colaboratory.intrinsic+json":{"type":"string"},"text/plain":["'Offline Usage'"]},"metadata":{"tags":[]},"execution_count":36}]},{"cell_type":"markdown","metadata":{"id":"Cb-sVEkyy8Et"},"source":["## Construct Dataset class\n","\n","We construct a PyTorch dataset class which aids in loading the pre-processed song lyrics.\n","\n","The pre-processed lyrics come with the following attributes:\n","\n","- `index2token`: Maps token integer ID to actual token\n","- `token2index`: Maps token to integer ID\n","- `counts`: Token frequencies\n","- `corpus`: List of tokenized lyrics for each sentence\n","- `vectors`: List of token ID tensors for each sentence"]},{"cell_type":"code","metadata":{"id":"BcdpCHU5y8Et"},"source":["class WorshipLyricDataset(torch.utils.data.Dataset):\n","    \"\"\"Worhip Song dataset from Genius.\n","    \"\"\"\n","\n","    def __init__(self, path: str):\n","\n","        # Load the pre-processed pickle file.\n","        with open(path, 'rb') as fp:\n","            store = pickle.load(fp)\n","        \n","        # Unpack the pickle.\n","        self.index2token = store['index2token']\n","        self.token2index = store['token2index']\n","        self.counts = store['counts']\n","        self.corpus = store['corpus']\n","        self.vectors = [torch.LongTensor(vec) for vec in store['vectors']]\n","        self.syllables = torch.nn.functional.one_hot(torch.LongTensor(store['syllables'])) # One-hot encoded syllabl counts.\n","\n","    def __len__(self):\n","        return len(self.vectors)\n","\n","    def __getitem__(self, idx):\n","        return (self.vectors[idx], self.syllables[idx],)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"tags":[],"id":"2qOn4O89y8Eu"},"source":["# Construct the data object.\n","dataset = WorshipLyricDataset(path=store_file)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"aHaxfleFDa0N"},"source":["# Split data into train/validation set.\n","n_records = len(dataset)\n","train_len = int(.8 * n_records)\n","test_len = int(.2 * n_records)\n","train_subset, test_subset = torch.utils.data.random_split(dataset, [train_len, test_len], generator=torch.Generator().manual_seed(42))"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"U8VO8Xnd1z4_"},"source":["To support training with variable-length sentences we must pad the input sentences on a per-batch basis. To do this in conjunction with a data loader, we define a \"collate\" function which pads the sentences within each batch."]},{"cell_type":"code","metadata":{"id":"IkJxCjVK_aTw"},"source":["def pad_collate(batch):\n","    \"\"\"Pad batches from dataloader.\n","\n","    This allows for more efficient padding,\n","    by only padding within each batch.\n","    \"\"\"\n","    sentences, syllables = zip(*batch)\n","    sen_lens = torch.LongTensor([len(vec) for vec in sentences])\n","    sen_pad = torch.nn.utils.rnn.pad_sequence(sentences, batch_first=True, padding_value=0)\n","    syllables = torch.stack(syllables) # Convert tuple of tensors to single 2D tensor.\n","    syllables = syllables.reshape(syllables.size(0),1,syllables.size(1)) # Convert to 3D.\n","    return (sen_pad,syllables,sen_lens,)"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"dc1BcftZ2GQb"},"source":["With the dataset and collation function defined we can now construct a `dataloader`, which will allow us to iterate over the lyrics dataset in batches. All training will be done using this loader object."]},{"cell_type":"code","metadata":{"id":"IFMjBBc4y8Ev"},"source":["# Construct data loader.\n","train_loader = torch.utils.data.DataLoader(train_subset, batch_size=32, shuffle=True, num_workers=2, collate_fn=pad_collate)\n","test_loader = torch.utils.data.DataLoader(test_subset, batch_size=32, shuffle=True, num_workers=2, collate_fn=pad_collate)"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"2XEogOJk_aTw"},"source":["## Model - RNN for Pure Next-word Prediction\n","\n","The anatomy of our model consts of:\n","\n","1. Embedding input layer\n","1. Unidirectional single-layer LSTM\n","1. Fully-connected output layer\n","\n","The model is generalized to support variable-length sequences by requiring inputs to be **zero-padded** and then it subsequently **packs** the padded input so that padding tokens are ignored by the internal LSTM layers.\n","\n","For each forward pass of the model it outputs the **current token prediction** (from the fully-connected layer), the **lengths of the sequence predictions** (required for packed padded input sequences), and the **LSTM output hidden and cell states**. This allows the LSTM hidden and cell states to be fed back into subsequent forward passes to retain sequence memory."]},{"cell_type":"code","metadata":{"id":"UQS_Mz8N_aTx"},"source":["class TokenRNN(torch.nn.Module):\n","    \"\"\"Sequence model for token prediction.\"\"\"\n","    def __init__(self, n_hidden: int, n_vocab: int, n_layers: int, dropout: float = 0., bidirectional: bool = False):\n","        super().__init__()\n","\n","        self.n_hidden = n_hidden\n","        self.n_vocab = n_vocab\n","        self.n_layers = n_layers\n","        self.bidirectional = bidirectional\n","        self.n_dir = 2 if bidirectional else 1\n","\n","        # Embedding layer.\n","        self.embed = torch.nn.Embedding(\n","            num_embeddings=n_vocab,\n","            embedding_dim=n_hidden,\n","        )\n","\n","        # LSTM layer.\n","        self.lstm = torch.nn.LSTM(\n","            input_size=n_hidden,\n","            hidden_size=n_hidden,\n","            num_layers=n_layers,\n","            dropout=dropout,\n","            bidirectional=bidirectional,\n","            batch_first=True,\n","            )\n","\n","        # Word mapping fully-connected layer.\n","        self.fc = torch.nn.Linear(in_features=n_hidden, out_features=n_vocab)\n","    \n","\n","    def forward(self, sentences: torch.Tensor, lens: torch.Tensor, hidden: torch.Tensor, cell: torch.Tensor):\n","        \"\"\"\n","        Args:\n","            sentences (torch.Tensor): Sentence word vectors.\n","            lens (torch.Tensor): True lengths of padded sentence vectors.\n","            hidden (torch.Tensor): Hidden state vector.\n","            cell (torch.Tensor): Cell state vector.\n","        \"\"\"\n","        \n","        # Embed the sentence vectors as floating-point.\n","        #\n","        # inputs: (batch_size, sentence_length,)\n","        sentences_embed = self.embed(sentences)\n","        # embedded: (batch_size, sentence_length, embed_dim,)\n","\n","        # Pack the embedding so that the paddings are ignored.\n","        sentences_embed_packed = torch.nn.utils.rnn.pack_padded_sequence(\n","            input=sentences_embed,\n","            lengths=lens, \n","            batch_first=True,\n","            enforce_sorted=False,\n","            )\n","\n","        # Pass the input feature vector as the first step.\n","        output_packed, (hidden, cell) = self.lstm(sentences_embed_packed, (hidden,cell,))\n","\n","        # Get padded output\n","        output_padded, output_lens = torch.nn.utils.rnn.pad_packed_sequence(output_packed, batch_first=True)\n","\n","        # Obtain token-level classification.\n","        output_padded_fc = self.fc(output_padded)\n","\n","        # Run packing on output layer.\n","        return output_padded_fc, output_lens, (hidden, cell,)\n","\n","    def init_hc(self, batch_size: int, device: str = 'cpu') -> torch.Tensor:\n","        \"\"\"Helepr to zero-initialize hidden and cell state tensors.\"\"\"\n","        return torch.zeros((self.n_layers*self.n_dir, batch_size, self.n_hidden), device=device)"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"_e9ODqNiy8Ew"},"source":["## Train\n","\n","Here we define some helper classes and functions for timing the training rounds."]},{"cell_type":"code","metadata":{"id":"7Fw74eIsy8Ex"},"source":["import time\n","from contextlib import contextmanager\n","\n","class timecontext:\n","    \"\"\"Elapsed time context manager.\"\"\"\n","    def __enter__(self):\n","        self.seconds = time.time()\n","        return self\n","    \n","    def __exit__(self, type, value, traceback):\n","        self.seconds = time.time() - self.seconds\n","\n","@contextmanager\n","def timecontextprint(description='Elapsed time'):\n","    \"\"\"Context manager to print elapsed time from call.\"\"\"\n","    with timecontext() as t:\n","        yield t\n","    print(f\"{description}: {t.seconds} seconds\")"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"rN445XAnnXlg"},"source":["The training itself is done by initializing the LSTM hidden and cell states to zero. Then to generalize all sentence structures we always set the first token to be run through the model as the start-of-sentence (SOS) token. \n","\n","To better generalize the next-token predictions we apply a technique known as \"teacher forcing\". In teacher forcing we pass the known next-token target value at each step as the input to the next RNN step. This forces the RNN to learn using the proper next-token rather than solely based on the predictions at each step. To increase generalization performance further we randomly apply teacher forcing for each batch based on a probability distribution (by default 50% probability). "]},{"cell_type":"code","metadata":{"id":"ib7AXBk3_aTy"},"source":["import random\n","from typing import List, Tuple\n","\n","def train(rnn, train_loader, test_loader, epochs, optimizer, criterion, device='cpu', teacher_force_ratio=0.5) -> Tuple[List[float],List[float]]:\n","    # Send model to device.\n","    rnn.to(device)\n","\n","    # Define loss lists.\n","    train_loss = []\n","    test_loss = []\n","\n","    # Compute batch lengths for averages.\n","    n_train = len(train_loader)\n","    n_test = len(test_loader)\n","\n","    for e in range(epochs):\n","\n","        # Train model.\n","        rnn.train()\n","        running_loss = 0.0\n","        for b,batch in enumerate(train_loader):\n","            sentences,_,sen_lens = batch\n","            sentences = sentences.to(device)\n","            sen_lens = sen_lens.to(device)\n","\n","            # Initialize hidden output.\n","            rnn_hidden = rnn.init_hc(32, device=device)\n","            rnn_cell = rnn.init_hc(32, device=device)\n","\n","            # Setup initial rnn inputs.\n","            SOS_token = dataset.token2index['<sos>']\n","            rnn_input = SOS_token*torch.ones((sentences.size(0), 1,), dtype=torch.long, device=device)\n","            rnn_input_lens = torch.ones((sentences.size(0),), dtype=torch.long)\n","\n","            # Initialize batch loss to zero.\n","            loss = 0\n","\n","            # Determine if teacher-forcing should be used for this batch.\n","            use_teacher_forcing = True if random.random() < teacher_force_ratio else False\n","\n","            # Teacher forcing.\n","            # Feed the target as the next input.\n","            if use_teacher_forcing:\n","                for target_idx in range(1, sentences.size(1)):\n","                    outputs, out_lens, (rnn_hidden, rnn_cell) = rnn(rnn_input, rnn_input_lens, rnn_hidden, rnn_cell)\n","\n","                    # Reshape outputs and targets to fit insize the criterion.\n","                    outputs = outputs.squeeze(dim=1)\n","                    targets = sentences[:,target_idx].reshape(sentences.size(0),-1)\n","\n","                    # Calculate batch loss.\n","                    loss += criterion(\n","                        outputs,\n","                        targets.squeeze(dim=1),\n","                    )\n","\n","                    # For teacher forcing set the input of the\n","                    # next round to be the current target.\n","                    rnn_input = targets.detach()\n","\n","            # No teacher forcing.\n","            # Feed the RNN predictions as the next input.\n","            else:\n","                for target_idx in range(1, sentences.size(1)):\n","                    outputs, out_lens, (rnn_hidden, rnn_cell) = rnn(rnn_input, rnn_input_lens, rnn_hidden, rnn_cell)\n","\n","                    # Get best prediction.\n","                    topv, topi = outputs.topk(1)\n","\n","                    # Reshape outputs and targets to fit insize the criterion.\n","                    outputs = outputs.squeeze(dim=1)\n","                    targets = sentences[:,target_idx].reshape(sentences.size(0),-1)\n","\n","                    # Calculate batch loss.\n","                    loss += criterion(\n","                        outputs,\n","                        targets.squeeze(dim=1),\n","                    )\n","\n","                    # Set the input of the next round to be the current prediction.\n","                    rnn_input = topi.squeeze(dim=-1).detach()\n","\n","            # Back-propagate, and step the optimizers.\n","            loss.backward()\n","            optimizer.step()\n","            \n","            # Zero the gradients\n","            optimizer.zero_grad()\n","\n","            # Accumulate the loss for this batch.\n","            running_loss += loss.item()\n","\n","        # Compute average loss.\n","        running_loss /= n_train\n","\n","        # Preserve training loss.\n","        train_loss.append(running_loss)\n","        print(f'[epoch {e}]: train loss {running_loss}')\n","\n","        # ---\n","\n","        # Validate models.\n","        rnn.eval()\n","        with torch.no_grad():\n","            running_loss = 0.0\n","            for b,batch in enumerate(test_loader):\n","                sentences,_,sen_lens = batch\n","                sentences = sentences.to(device)\n","                sen_lens = sen_lens.to(device)\n","\n","                # Initialize hidden output.\n","                rnn_hidden = rnn.init_hc(32, device=device)\n","                rnn_cell = rnn.init_hc(32, device=device)\n","\n","                # Setup initial rnn inputs.\n","                SOS_token = dataset.token2index['<sos>']\n","                rnn_input = SOS_token*torch.ones((sentences.size(0), 1,), dtype=torch.long, device=device)\n","                rnn_input_lens = torch.ones((sentences.size(0),), dtype=torch.long)\n","\n","                # Initialize batch loss to zero.\n","                loss = 0\n","\n","                # Feed prediction as next-input.\n","                for target_idx in range(1, sentences.size(1)):\n","                    outputs, out_lens, (rnn_hidden, rnn_cell) = rnn(rnn_input, rnn_input_lens, rnn_hidden, rnn_cell)\n","\n","                    # Get best prediction.\n","                    topv, topi = outputs.topk(1)\n","\n","                    # Reshape outputs and targets to fit insize the criterion.\n","                    outputs = outputs.squeeze(dim=1)\n","                    targets = sentences[:,target_idx].reshape(sentences.size(0),-1)\n","\n","                    # Calculate batch loss.\n","                    loss += criterion(\n","                        outputs,\n","                        targets.squeeze(dim=1),\n","                    )\n","\n","                    # Set the input of the next round to be the current prediction.\n","                    rnn_input = topi.squeeze(dim=-1).detach()\n","                \n","                # Accumulate the loss for this batch.\n","                running_loss += loss.item()\n","\n","            # Compute average loss.\n","            running_loss /= n_test\n","\n","            # Preserve testing loss.\n","            test_loss.append(running_loss)\n","            print(f'[epoch {e}]: test loss {running_loss}')\n","\n","\n","    # Return list of losses for epochs.\n","    return train_loss, test_loss"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"2fPRgo--_aTy"},"source":["# Length of vocabulary.\n","n_words = len(dataset.index2token)\n","\n","# RNN.\n","rnn = TokenRNN(\n","    n_vocab=n_words,\n","    n_hidden=256,\n","    n_layers=1,\n",")"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"h0wo-azdpYoj"},"source":["To speed-up training PyTorch allows us to leverage a GPU, using CUDA, if one is available. Since training a CNN can be computationally intensive we prefer to use a GPU for speed, but will revert to using the CPU if necessary."]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"AcoqyU4X_aTy","executionInfo":{"status":"ok","timestamp":1619640691340,"user_tz":240,"elapsed":1555,"user":{"displayName":"Alexander DeRieux","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GjXMvSXQtaWB75iKecg6p0SbX3z5jmeUWh8Esnzkg=s64","userId":"11983099067437663618"}},"outputId":"a522d5d4-56c2-4cd9-e001-f629c7950580"},"source":["# Set runtime device.\n","device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n","print(f\"Device: {device}\")"],"execution_count":null,"outputs":[{"output_type":"stream","text":["Device: cuda\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"qrwgQjIs2kp3"},"source":["With the model defined we can now train it on the lyrics dataset.\n","\n","We define a set of training hyperparameters `epochs` and `lr` which are number of training iterations and optimizer learning rate respectively.\n","\n","For training we use the `Adam` optimizer and `CrossEntropyLoss` criterion since each next-token prediction is essentially a classification task.\n","\n","To speed-up subsequent runs, we also save the trained model to a file. This allows us to train the model once, and then simply load the pre-trained model (using the flag `load_from_file = True`) if the Jupyter notebook is run multiple times during a single session."]},{"cell_type":"code","metadata":{"tags":[],"colab":{"base_uri":"https://localhost:8080/"},"id":"lCfDO1Ko_aTz","executionInfo":{"status":"ok","timestamp":1619640691341,"user_tz":240,"elapsed":1532,"user":{"displayName":"Alexander DeRieux","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GjXMvSXQtaWB75iKecg6p0SbX3z5jmeUWh8Esnzkg=s64","userId":"11983099067437663618"}},"outputId":"af6baa71-d7ba-4a56-fe49-13afb5671c21"},"source":["import numpy as np\n","\n","# Define path to RNN model storage.\n","load_from_file = True\n","rnn_store = os.path.join(root_path, dataset_path, 'rnn_nsyl.pt')\n","loss_store = os.path.join(root_path, dataset_path, 'loss_nsyl.npy')\n","\n","# Load model from store file.\n","if load_from_file and os.path.exists(rnn_store) and os.path.exists(loss_store):\n","    print(f'Loading RNN model: {rnn_store}')\n","    rnn.load_state_dict(torch.load(rnn_store))\n","\n","    # Read losses from file.\n","    print(f'Loading RNN losses: {loss_store}')\n","    with open(loss_store, 'rb') as fp:\n","       train_loss_rounds, test_loss_rounds = np.load(fp)\n","\n","else:\n","    # Learning parameters.\n","    rounds = 10\n","    epochs = 10\n","    lr = 1e-3\n","    print(f'Training RNN model: rounds={rounds}, epochs={epochs}, lr={lr}, batches={len(train_loader)}')\n","\n","    # Train the model.\n","    # Display training time too.\n","    train_loss_rounds = []\n","    test_loss_rounds = []\n","    with timecontextprint():\n","        optimizer = torch.optim.Adam(rnn.parameters(), lr=lr)\n","        criterion = torch.nn.CrossEntropyLoss(reduction='mean')\n","        for round in range(rounds):\n","            with timecontextprint(f\"[round {round}] elapsed time\"):\n","                train_loss, test_loss = train(rnn,\n","                    train_loader=train_loader,\n","                    test_loader=test_loader,\n","                    epochs=epochs,\n","                    optimizer=optimizer,\n","                    criterion=criterion,\n","                    device=device,\n","                )\n","                train_loss_rounds.append(train_loss)\n","                test_loss_rounds.append(test_loss)\n","\n","            # Store model state to file.\n","            torch.save(rnn.state_dict(), rnn_store)\n","            print(f'[round {round}] saved model: {rnn_store}')\n","\n","            # Save losses to file too.\n","            with open(loss_store, 'wb') as fp:\n","                np.save(fp, [train_loss_rounds, test_loss_rounds])\n","\n","    train_loss_rounds = np.array(train_loss_rounds) # Convert to numpy array.\n","    test_loss_rounds = np.array(test_loss_rounds) # Convert to numpy array."],"execution_count":null,"outputs":[{"output_type":"stream","text":["Loading RNN model: /content/gdrive/My Drive/Virginia Tech/graduate/courses/2021_spring/ece_5424/assignments/project_ece_5424/./dataset/rnn_nsyl.pt\n","Loading RNN losses: /content/gdrive/My Drive/Virginia Tech/graduate/courses/2021_spring/ece_5424/assignments/project_ece_5424/./dataset/loss_nsyl.npy\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/","height":279},"id":"1dNq9vmcFTlm","executionInfo":{"status":"ok","timestamp":1619640691708,"user_tz":240,"elapsed":1875,"user":{"displayName":"Alexander DeRieux","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GjXMvSXQtaWB75iKecg6p0SbX3z5jmeUWh8Esnzkg=s64","userId":"11983099067437663618"}},"outputId":"2f714037-c91f-4992-b177-9a892b7a3263"},"source":["# Plot the losses\n","import matplotlib.pyplot as plt\n","plt.plot(train_loss_rounds.flatten(), label='Train')\n","plt.plot(test_loss_rounds.flatten(), label='Test')\n","plt.xlabel('Epoch')\n","plt.ylabel('Loss')\n","plt.legend()\n","plt.savefig(os.path.join(root_path,dataset_path,'loss_nsyl.png'), dpi=150, bbox_inches='tight')"],"execution_count":null,"outputs":[{"output_type":"display_data","data":{"image/png":"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\n","text/plain":["<Figure size 432x288 with 1 Axes>"]},"metadata":{"tags":[],"needs_background":"light"}}]},{"cell_type":"markdown","metadata":{"id":"rNCyPzcSy8Ez"},"source":["## Evaluate\n","\n","Now that the model has been trained we can use it to generate song lyrics.\n","\n","We define a helper function to evaluate the RNN model. The process of RNN evaluation is actually very similar to training. The difference is that for each token prediction we randomly choose the predicted token based on the normalized probability distribution of the prediction set. We also do not employ teacher forcing since the next-token at each step is unknown.\n","\n","The evaluation process continuously loops through next-token predictions until either an end-of-sentence (EOS) token or a maximum predicted token length is reached."]},{"cell_type":"code","metadata":{"id":"QCzrY_eKDi7H"},"source":["def evaluate(rnn, seed='<sos>', max_length=None, device='cpu') -> List[str]:\n","    \"\"\"Generate a sequence of tokens using the TokenRNN and a starting seed.\"\"\"\n","    rnn.to(device)\n","    rnn.eval()\n","    with torch.no_grad():\n","\n","        # Initialize hidden output.\n","        rnn_hidden = rnn.init_hc(1, device=device)\n","        rnn_cell = rnn.init_hc(1, device=device)\n","\n","        # Setup initial rnn inputs.\n","        EOS_index = dataset.token2index['<eos>']\n","        SOS_index = dataset.token2index['<sos>']\n","        seed_token = dataset.token2index.get(seed, SOS_index)\n","        rnn_input = seed_token*torch.ones((1, 1,), dtype=torch.long, device=device)\n","        rnn_input_lens = torch.ones((1,), dtype=torch.long)\n","\n","        # Always initialize the deocded tokens with an SOS token.\n","        tokens = [seed]\n","\n","        # Loop indefinitely until token list is generated.\n","        while True:\n","\n","            # Run current inputs, hidden and cell states through the RNN.\n","            outputs, out_lens, (rnn_hidden, rnn_cell) = rnn(rnn_input, rnn_input_lens, rnn_hidden, rnn_cell)\n","\n","            # Normalize the probability distribution of the current prediction.\n","            probs = np.array(torch.nn.functional.softmax(outputs, dim=2).squeeze().cpu())\n","            probs = probs / probs.sum()\n","\n","            # Choose the top prediction from the normalized probability disrtribution above.\n","            topi = torch.tensor(np.random.choice(rnn.n_vocab, 1, p=probs, replace=False), dtype=torch.long, device=device).view(1,1,1)\n","\n","            # Add the current token to the predicted token list.\n","            tokens.append(dataset.index2token[topi.item()])\n","\n","            # Stop if current token is EOS or maximum sentence length has been reached.\n","            if (topi.item() == EOS_index) or (max_length and len(tokens) == max_length):\n","                break\n","\n","            # Set the input of the next round to be the current prediction.\n","            rnn_input = topi.squeeze(dim=-1).detach()\n","\n","        return tokens"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"ykEZeefsuvb2"},"source":["We also define a helper function to generate song lyrics, composed of multiple lines, by inputting a set of line-count, optional maximum sentence length, and optional seed list for each sentence. This generates a sequence of tokens for each line of the song and then subsequently joins all lines into a single newline-delimited string."]},{"cell_type":"code","metadata":{"id":"rAi8p8CP_aT0"},"source":["def generate_song(num_lines: int, max_length: int = None, seeds: list = None) -> str:\n","    \"\"\"Helper to generate song lyrics given constraints.\"\"\"\n","\n","    # Build list of line seeds if none were provided.\n","    seed = '<sos>'\n","    if not seeds:\n","        seeds = [seed]*num_lines\n","\n","    # Generate predictions for each line.\n","    lines = []\n","    for i in range(num_lines):\n","        tokens = evaluate(rnn, max_length=max_length, seed=seeds[i], device=device)\n","        if tokens[0] != '<sos>': tokens = ['<sos>'] + tokens\n","        lines.append(' '.join(tokens))\n","\n","    # Join lines together and return as single string.\n","    return '\\n'.join(lines)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"omsy3YOj_aT0","executionInfo":{"status":"ok","timestamp":1619640691709,"user_tz":240,"elapsed":1846,"user":{"displayName":"Alexander DeRieux","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GjXMvSXQtaWB75iKecg6p0SbX3z5jmeUWh8Esnzkg=s64","userId":"11983099067437663618"}},"outputId":"d07f9edd-255a-4887-8d30-a748aa83c1db"},"source":["print(generate_song(num_lines=3, max_length=10))"],"execution_count":null,"outputs":[{"output_type":"stream","text":["<sos> my expectation <eos>\n","<sos> never will never stop never stop working <eos>\n","<sos> will give you everything say the way <eos>\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"zXuEKFKz_aT1","executionInfo":{"status":"ok","timestamp":1619640691710,"user_tz":240,"elapsed":1823,"user":{"displayName":"Alexander DeRieux","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GjXMvSXQtaWB75iKecg6p0SbX3z5jmeUWh8Esnzkg=s64","userId":"11983099067437663618"}},"outputId":"1c147c86-32c6-494d-fd0c-2a89027a6284"},"source":["print(generate_song(num_lines=3, seeds=['god', 'we', 'they']))"],"execution_count":null,"outputs":[{"output_type":"stream","text":["<sos> god bursting healer <eos>\n","<sos> we deserved no name above every part was so other other name <eos>\n","<sos> they did not run <eos>\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"65_gGRFgNZKG","executionInfo":{"status":"ok","timestamp":1619640692237,"user_tz":240,"elapsed":2326,"user":{"displayName":"Alexander DeRieux","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GjXMvSXQtaWB75iKecg6p0SbX3z5jmeUWh8Esnzkg=s64","userId":"11983099067437663618"}},"outputId":"88b9644f-09fa-4f24-ea0f-c6d2e6d181bf"},"source":["print(generate_song(num_lines=3, seeds=['we', 'give', 'you',]))"],"execution_count":null,"outputs":[{"output_type":"stream","text":["<sos> we worthless travel owe sand <eos>\n","<sos> give thanks for you <eos>\n","<sos> you ever take good <eos>\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"yH64j5Rs9LEZ"},"source":["Now let's generate a list of 3-line songs and save them to a file."]},{"cell_type":"code","metadata":{"id":"wbO3PT46Ne8O"},"source":["import os\n","import random\n","\n","n_songs = 10\n","num_lines = 3\n","outfile = os.path.join(root_path, dataset_path, 'gen_lyrics_nonsyl.txt')\n","overwrite = False\n","if overwrite or not os.path.exists(outfile):\n","    with open(outfile, 'w') as fp:\n","        for n in range(n_songs):\n","            lyrics = generate_song(num_lines=num_lines)\n","            fp.write(lyrics + '\\n\\n')\n","            print(lyrics + '\\n')"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"tBXpR_QnEijT"},"source":["Now lets check the accuracy of the sentences. To do this we will compute the Bilingual Evaluation Understudy Score (BLEU). The BLEU is a metric for evaluating a generated sentence w.r.t. a refernce sentence."]},{"cell_type":"code","metadata":{"id":"XQj933M9R5Rz"},"source":["from itertools import zip_longest\n","def grouper(n, iterable, fillvalue=None):\n","    \"\"\"Gleaned from: http://docs.python.org/library/itertools.html#recipes\"\"\"\n","    args = [iter(iterable)]*n\n","    return zip_longest(fillvalue=fillvalue, *args)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"Zqep0yh1CXjb","executionInfo":{"status":"ok","timestamp":1619640719464,"user_tz":240,"elapsed":29534,"user":{"displayName":"Alexander DeRieux","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GjXMvSXQtaWB75iKecg6p0SbX3z5jmeUWh8Esnzkg=s64","userId":"11983099067437663618"}},"outputId":"7c8f3203-beda-4b6a-d1ea-024339757952"},"source":["from nltk.translate.bleu_score import sentence_bleu, SmoothingFunction\n","import ast\n","\n","n_songs = 10\n","rng = (5, 11) # Random syllable count range\n","scores = []\n","with open(outfile, 'r') as fp:\n","    lines = [l.strip() for l in fp.readlines() if l.strip()]\n","    for s,tup in enumerate(grouper(3, lines)):\n","        lyrics = [l.split(' ')[1:] for l in tup] # Split on whitespace and remove \"<sos>\" token.\n","        for i,l in enumerate(lyrics):\n","            cc = SmoothingFunction()\n","            score = sentence_bleu(dataset.corpus, l, smoothing_function=cc.method4)\n","            scores.append(score)\n","            print(f\"[song={s}, line={i}] BLEU={score}, sentence={l}\")\n","\n","# Compute total BLEU score across all runs.\n","total_score = sum(scores)\n","print(f\"Total score: {total_score} BLEU ({len(scores)} candidates)\")"],"execution_count":null,"outputs":[{"output_type":"stream","text":["[song=0, line=0] BLEU=1.0, sentence=['you', 'to', 'come', 'and', 'have', 'your', 'way', '<eos>']\n","[song=0, line=1] BLEU=1.0, sentence=['my', 'god', 'is', 'the', 'ancient', 'of', 'days', '<eos>']\n","[song=0, line=2] BLEU=1.0, sentence=['god', 'there', 'is', 'no', 'one', 'more', 'wonderful', '<eos>']\n","[song=1, line=0] BLEU=0.43224625083098384, sentence=['over', 'us', '<eos>']\n","[song=1, line=1] BLEU=0.43224625083098384, sentence=['from', 'bondage', '<eos>']\n","[song=1, line=2] BLEU=1.0, sentence=['be', 'with', 'you', '<eos>']\n","[song=2, line=0] BLEU=1.0, sentence=['chain', 'that', 'held', 'me', 'bound', 'is', 'broken', '<eos>']\n","[song=2, line=1] BLEU=0.7598356856515925, sentence=['beat', 'is', 'yours', 'you', 'can', 'be', 'secure', '<eos>']\n","[song=2, line=2] BLEU=0.4518010018049224, sentence=['are', '<unk>', 'the', 'ones', 'you', 'love', 'made', '<eos>']\n","[song=3, line=0] BLEU=1.0, sentence=['if', 'where', 'i', 'tried', 'to', 'go', 'was', 'always', 'here', '<eos>']\n","[song=3, line=1] BLEU=0.37848101197147527, sentence=['strength', 'to', '<unk>', 'us', 'to', 'him', '<eos>']\n","[song=3, line=2] BLEU=1.0, sentence=['delight', 'myself', 'in', 'you', '<eos>']\n","[song=4, line=0] BLEU=1.0, sentence=['will', 'not', 'leave', 'me', 'in', 'ruins', 'you', 'will', 'not', 'leave', 'me', 'alone', '<eos>']\n","[song=4, line=1] BLEU=0.13374394457703614, sentence=['<unk>', '<unk>', '<eos>']\n","[song=4, line=2] BLEU=0.4833575318592416, sentence=['storm', 'he', 'has', 'said', '<eos>']\n","[song=5, line=0] BLEU=0.43224625083098384, sentence=['takes', 'away', '<eos>']\n","[song=5, line=1] BLEU=1.0, sentence=['it', 'is', 'okay', '<eos>']\n","[song=5, line=2] BLEU=1.0, sentence=['that', 'i', 'am', '<eos>']\n","[song=6, line=0] BLEU=1.0, sentence=['as', 'eres', 't', 'seor', '<eos>']\n","[song=6, line=1] BLEU=0.5721248424548514, sentence=['the', 'all', 'of', 'my', 'life', 'for', 'all', 'who', '<unk>', '<eos>']\n","[song=6, line=2] BLEU=1.0, sentence=['are', 'the', 'god', 'of', 'peace', 'jesus', '<eos>']\n","[song=7, line=0] BLEU=0.4234197579236933, sentence=['i', 'chain', 'that', 'is', '<unk>', 'out', 'of', 'my', 'door', '<eos>']\n","[song=7, line=1] BLEU=0.3833076531642739, sentence=['goodness', 'is', 'for', 'my', '<unk>', '<eos>']\n","[song=7, line=2] BLEU=0.5245002946223603, sentence=['way', 'it', 'all', '<eos>']\n","[song=8, line=0] BLEU=0.43224625083098384, sentence=['have', 'tasted', '<eos>']\n","[song=8, line=1] BLEU=1.0, sentence=['are', 'our', 'one', 'desire', '<eos>']\n","[song=8, line=2] BLEU=1.0, sentence=['blood', 'is', 'making', 'all', 'things', 'new', '<eos>']\n","[song=9, line=0] BLEU=1.0, sentence=['that', 'this', 'time', 'in', 'my', 'life', 'is', 'just', 'a', 'season', '<eos>']\n","[song=9, line=1] BLEU=0.9621954581957615, sentence=['would', 'hate', 'to', 'see', 'you', 'give', 'up', 'on', 'me', '<eos>']\n","[song=9, line=2] BLEU=1.0, sentence=['heart', 'your', 'ways', '<eos>']\n","Total score: 22.801752185549145 BLEU (30 candidates)\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"Q-PgXOQcEAL8"},"source":[""],"execution_count":null,"outputs":[]}]}