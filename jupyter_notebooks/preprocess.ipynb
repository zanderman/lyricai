{
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.2"
  },
  "orig_nbformat": 2,
  "kernelspec": {
   "name": "python392jvsc74a57bd064d019df8f386dcc423f9fd084afce6ddb1bf16f9fb1fd7275a3007e4feb955b",
   "display_name": "Python 3.9.2 64-bit ('lyricai-GYvo4rtv': pipenv)"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2,
 "cells": [
  {
   "source": [
    "# Data Pre-processing"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 186,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import json"
   ]
  },
  {
   "source": [
    "## Load lyric files"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 187,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_path = '../../dataset'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 188,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_song_files(root_dir: str) -> dict:\n",
    "    return {int(os.path.splitext(os.path.basename(f))[0]): os.path.join(root_dir, f) for f in os.listdir(root_dir) if f.endswith('.json')}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 189,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_songs(file_dict: dict):\n",
    "    song_dict = {}\n",
    "    for song_id, path in file_dict.items():\n",
    "        with open(path, 'r') as fp:\n",
    "            song_dict[song_id] = json.load(fp)\n",
    "    return song_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 190,
   "metadata": {},
   "outputs": [],
   "source": [
    "songid_to_file = get_song_files(os.path.join(dataset_path,'songs'))\n",
    "songid_to_song = load_songs(songid_to_file)"
   ]
  },
  {
   "source": [
    "## Cleanse lyrics"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 191,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import collections\n",
    "import itertools\n",
    "import pickle\n",
    "import re\n",
    "from typing import List\n",
    "import nltk\n",
    "\n",
    "class LyricsVocab:\n",
    "    # List of tokens that have reserved corpus index.\n",
    "    reserved_tokens = ['<pad>', '<start>', '<end>', '<unk>']\n",
    "\n",
    "    def __init__(self, songs: dict):\n",
    "\n",
    "        # Process each song into list of words for each line.\n",
    "        self.songid2lyrics = {songid: self.clean_lyrics(song['lyrics']) for songid,song in songs.items()}\n",
    "\n",
    "        # Flatten all lyrics into single list.\n",
    "        flat = list(self.flatten_multi_list([lyrics for songid,lyrics in self.songid2lyrics.items()]))\n",
    "\n",
    "        # Generate counts for each word.\n",
    "        self.counts = collections.Counter(flat)\n",
    "\n",
    "        # Generate list of unique words.\n",
    "        self.corpus = self.reserved_tokens + sorted(set(flat))\n",
    "\n",
    "        # Build mappings for: int <--> token\n",
    "        self.token2index = {}\n",
    "        self.index2token = {}\n",
    "        for i,token in enumerate(self.corpus):\n",
    "            self.token2index[token] = i\n",
    "            self.index2token[i] = token\n",
    "\n",
    "        # Generate embedding based on word assignment.\n",
    "        self.songid2embed = {songid: [[self.token2index[token] for token in line] for line in lyrics] for songid,lyrics in self.songid2lyrics.items()}\n",
    "\n",
    "    def save(self, path: str, protocol: int = pickle.DEFAULT_PROTOCOL):\n",
    "        \"\"\"Save vocabulary to a pickle file.\n",
    "        \n",
    "        The pickle file is a dictionary which contains the following keys:\n",
    "            index2token: Dictionary of index --> token\n",
    "            embed: Dictionary of song ID --> 2D list for lyric integer tokens\n",
    "            counts: Dictionary of token --> number of occurrences\n",
    "        \"\"\"\n",
    "        store = {\n",
    "            'index2token': self.index2token,\n",
    "            'token2index': self.token2index,\n",
    "            'embed': self.songid2embed,\n",
    "            'counts': self.counts,\n",
    "        }\n",
    "        with open(path, 'wb') as fp:\n",
    "            pickle.dump(store, fp, protocol=protocol)\n",
    "\n",
    "    @classmethod\n",
    "    def flatten_multi_list(cls, ml: list):\n",
    "        for l in ml:\n",
    "            if isinstance(l, list):\n",
    "                yield from cls.flatten_multi_list(l)\n",
    "            else:\n",
    "                yield l\n",
    "\n",
    "    @staticmethod\n",
    "    def decontracted(phrase: str):\n",
    "        \"\"\"Remove English word contractions.\n",
    "\n",
    "        Gleaned from: https://stackoverflow.com/a/47091490\n",
    "        \"\"\"\n",
    "        # specific\n",
    "        phrase = re.sub(r\"won\\'t\", \"will not\", phrase)\n",
    "        phrase = re.sub(r\"can\\'t\", \"can not\", phrase)\n",
    "        phrase = re.sub(r\"wanna\", \"want to\", phrase)\n",
    "        phrase = re.sub(r\"gotta\", \"got to\", phrase)\n",
    "\n",
    "        # general\n",
    "        phrase = re.sub(r\"n\\'t\", \" not\", phrase)\n",
    "        phrase = re.sub(r\"\\'re\", \" are\", phrase)\n",
    "        phrase = re.sub(r\"\\'s\", \" is\", phrase)\n",
    "        phrase = re.sub(r\"\\'d\", \" would\", phrase)\n",
    "        phrase = re.sub(r\"\\'ll\", \" will\", phrase)\n",
    "        phrase = re.sub(r\"\\'t\", \" not\", phrase)\n",
    "        phrase = re.sub(r\"\\'ve\", \" have\", phrase)\n",
    "        phrase = re.sub(r\"\\'m\", \" am\", phrase)\n",
    "        return phrase\n",
    "\n",
    "    @classmethod\n",
    "    def clean_lyrics(cls, lyric: str) -> List[List[str]]:\n",
    "        lyric = lyric.lower() # Convert to common case.\n",
    "        lyric = re.sub(r'\\[[^\\]]*\\]', '', lyric) # Remove paranthetical content \"[*]\", like markers for chorus and verses.\n",
    "        lyric = re.sub(r'\\([^\\)]*\\)', '', lyric) # Remove paranthetical content \"(*)\", like markers for chorus and verses.\n",
    "        lyric = lyric.strip() # Remove any extra newlines at the ends.\n",
    "        lyric = cls.decontracted(lyric) # Remove contractions before tokenizer to handle special cases.\n",
    "\n",
    "        # Preserve line structure because tokenizer will remove traditional newlines.\n",
    "        lyric = re.sub(r\"(?:\\s*\\n\\s*)+\", r'\\n', lyric) # Remove repeated newlines.\n",
    "        lyric = re.sub('\\n', ' NEWLINE ', lyric)\n",
    "\n",
    "        # Tokenize the entire song into list of words.\n",
    "        tokens = nltk.tokenize.word_tokenize(lyric) # Split into word tokens.\n",
    "        tokens = [word for word in tokens if word.isalpha()] # Careful to remove punct after contractions.\n",
    "\n",
    "        # Group sentences together by line.\n",
    "        tokens_lines = list(list(group) for key,group in itertools.groupby(tokens, lambda s: s == 'NEWLINE') if not key)\n",
    "        return tokens_lines"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 192,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Create vocabulary object.\n",
    "lv = LyricsVocab(songid_to_song)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 193,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "1339 songs\n6275 unique words\n"
     ]
    }
   ],
   "source": [
    "print(f\"{len(lv.songid2lyrics)} songs\")\n",
    "print(f\"{len(lv.corpus)} unique words\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 194,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Song:      ['stepping', 'out', 'in', 'faith']\nEmbedding: [5047, 3648, 2690, 1858]\n"
     ]
    }
   ],
   "source": [
    "songid = list(lv.songid2lyrics.keys())[0]\n",
    "print(f\"Song:      {lv.songid2lyrics[songid][0]}\")\n",
    "print(f\"Embedding: {lv.songid2embed[songid][0]}\")"
   ]
  },
  {
   "source": [
    "## Write embedding to pickle file"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 195,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Lyrics vocabulary saved: ../../dataset/lyrics.pickle\n"
     ]
    }
   ],
   "source": [
    "path = os.path.join(dataset_path, 'lyrics.pickle')\n",
    "lv.save(path)\n",
    "print(f'Lyrics vocabulary saved: {path}')"
   ]
  }
 ]
}